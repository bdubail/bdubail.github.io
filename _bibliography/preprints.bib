@article{cutoff_reversible,
      TY={ARXIV},
      title={Cutoff for mixtures of permuted Markov chains: reversible case}, 
      author={Bastien Dubail},
      year={2024},
      abstract={We investigate the mixing properties of a model of reversible Markov chains in random environment, which notably contains the simple random walk on the superposition of a deterministic graph and a second graph whose vertex set has been permuted uniformly at random. It generalizes in particular a result of Hermon, Sly and Sousi, who proved the cutoff phenomenon at entropic time for the simple random walk on a graph with an added uniform matching. Under mild assumptions on the base Markov chains, we prove that with high probability the resulting chain exhibits the cutoff phenomenon at entropic time $\log n / h$, $h$ being some constant related to the entropy of the chain. We note that the results presented here are the consequence of a work conducted for a more general model that does not assume reversibility, which will be the object of a companion paper. Thus, most of our proofs do not actually require reversibility, which constitutes an important technical contribution. Finally, our argument relies on a novel concentration result for "low-degree" functions on the symmetric group, established specifically for our purpose but which could be of independent interest. },
      arxiv={2401.03937},
      pdf={https://arxiv.org/pdf/2401.03937.pdf},
      archivePrefix={arXiv},
      primaryClass={math.PR},
      note={In revision in Annals of Applied Probability}
}

@article{cutoff_general,
      TYPE={ARXIV},
      title={Cutoff for mixtures of permuted Markov chains: general case}, 
      author={Bastien Dubail},
      year={2024},
      abstract={We investigate the mixing properties of a finite Markov chain in random environment defined as a mixture of a deterministic chain and a chain whose state space has been permuted uniformly at random. This work is the counterpart of a companion paper where we focused on a reversible model, which allowed for a few simplifications in the proof. We consider here the general case. Under mild assumptions on the base Markov chains, we prove that with high probability the resulting chain exhibits the cutoff phenomenon at entropic time $\log n / h$,  $h$ being some constant related to the entropy of the chain, when the chain is started from a typical state. However contrary to the reversible case uniform cutoff at entropic time does not hold, as we provide an example where the worst-case mixing time has at least polylogarithmic order. We also provide a polylogarithmic upper bound on the worst-case mixing time, which in fact plays a crucial role in deriving the main result for typical states. Incidentally, our proof gives a clear picture of when to expect uniform cutoff at entropic time: it appears as the consequence of a uniform transience property for the covering Markov chain used throughout the proof, which lies on an infinite state space and projects back onto the initial chain. },
      arxiv={2402.03415},
      pdf={https://arxiv.org/pdf/2402.03415.pdf},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}

@article{shift_lowrank,
      TY={ARXIV},
      title={Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning}, 
      author={Bastien Dubail and Stefan Stojanovic and Alexandre Proutière},
      year={2025},
      abstract = {Low-rank structure is a common implicit assumption in many modern reinforcement learning (RL) algorithms. For instance, reward-free and goal-conditioned RL methods often presume that the successor measure admits a low-rank representation. In this work, we challenge this assumption by first remarking that the successor measure itself is not low-rank. Instead, we demonstrate that a low-rank structure naturally emerges in the shifted successor measure, which captures the system dynamics after bypassing a few initial transitions. We provide finite-sample performance guarantees for the entry-wise estimation of a low-rank approximation of the shifted successor measure from sampled entries. Our analysis reveals that both the approximation and estimation errors are primarily governed by the so-called spectral recoverability of the corresponding matrix. To bound this parameter, we derive a new class of functional inequalities for Markov chains that we call Type II Poincaré inequalities and from which we can quantify the amount of shift needed for effective low-rank approximation and estimation. This analysis shows in particular that the required shift depends on decay of the high-order singular values of the shifted successor measure and is hence typically small in practice. Additionally, we establish a connection between the necessary shift and the local mixing properties of the underlying dynamical system, which provides a natural way of selecting the shift. Finally, we validate our theoretical findings with experiments, and demonstrate that shifting the successor measure indeed leads to improved performance in goal-conditioned RL.},
      arxiv={2509.05193},
      pdf={https://arxiv.org/pdf/2509.05193.pdf},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      note={Accepted as Spotlight at NeurIPS 2025}
}



